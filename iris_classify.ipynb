{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e206f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\samsung\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samsung\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd559a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26575eb2",
   "metadata": {},
   "source": [
    "### 모듈 호츨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8941070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f6b8a",
   "metadata": {},
   "source": [
    "### 데이터 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59dedc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target 값 :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target 명 :  ['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "iris = load_iris()\n",
    "# iris.data 는 iris 데이터에서 피처만으로 된 데이터를 numpy로 가지고 있음.\n",
    "iris_data = iris.data \n",
    "# iris.target 은 iris 데이터 세트에서 레이블(결정 값) 데이터를 numpy로 가지고 있음,\n",
    "iris_label = iris.target\n",
    "print('iris target 값 : ', iris_label)\n",
    "print('iris target 명 : ', iris.target_names)\n",
    "\n",
    "# Df로 변환\n",
    "iris_df = pd.DataFrame(data = iris_data, columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9cb97b",
   "metadata": {},
   "source": [
    "' 피처에는 꽃잎 길이 , 너비 , 꽃받침 길이 ,너비 ,   \n",
    "label은 0 , 1, 2, 세가지 값  (0 : setosa , 1 : versicolor , 2: virginica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db54421",
   "metadata": {},
   "source": [
    "### 학습 데이터 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18889950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(iris_data, iris_label, \n",
    "                                                  test_size =0.2 , random_state =11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbce91",
   "metadata": {},
   "source": [
    "### 객체생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02719096",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state =11)\n",
    "# 학습 fit()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "# 예측 수행\n",
    "y_hat = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7de5e",
   "metadata": {},
   "source": [
    "### 예측성능 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5f26c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9333\n"
     ]
    }
   ],
   "source": [
    "# metrics 모듈의 accuracy_score( 정확도  측정)\n",
    "from sklearn.metrics import accuracy_score\n",
    "# y_tset: 실제 데이터 , y_hat : 예측데이터\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test,y_hat)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50304a90",
   "metadata": {},
   "source": [
    "### Model Selection 모듈 \n",
    "학습데이터와 검증 데이터 분리 , 교차검증 부할 및 평가   \n",
    "or Estimator의 하이퍼 파라미터 튜닝 하기 위한 다양한 함수 및 클래스 제공 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5dba48",
   "metadata": {},
   "source": [
    "#### train_test_split() : 학습데이터 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a570283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터 세트로만 학습하고 예측 (분리 x )\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "# 학습\n",
    "dt_clf.fit(train_data,train_label)\n",
    "# 예측\n",
    "pred = dt_clf.predict(train_data)\n",
    "print(accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa89b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분리 \n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \n",
    "                                                  test_size =0.3 , random_state =121)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe54851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 예측 \n",
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도 : {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bf12e",
   "metadata": {},
   "source": [
    "### 교차검증 \n",
    "과적합 문제 -> 교차검증 : 여러 세트로 구성된 학습데이터와 검증 데이터 세트에서 학습과 평가 수행  \n",
    "학습데이터를 다시한번 더 분할 \n",
    "#####  K 폴드 교차검증 : KFold 클래스 , stratifiedKFold 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782d6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold  # 분할이 kfold \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cc9483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "features =iris.data  # X 데이터 셋 \n",
    "label = iris.target  # Y 분류 레이블 값 \n",
    "dt_clf = DecisionTreeClassifier(random_state = 156) \n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 Kfold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성 \n",
    "kfold = KFold(n_splits = 5)   # 5개로 분할 \n",
    "cv_accuracy = []\n",
    "print('붓꽃 데이터 세트의 크기 :', features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49619f6",
   "metadata": {},
   "source": [
    "##### 분리\n",
    "150개 데이터 -> 5 분할 , 120 (학습용) / 30 (검증용), 5번 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02744048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차검증 정확도:1.0, 학습데이터 크기 : 120, 검증데이터 크기: 30\n",
      "#1 검증세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차검증 정확도:0.9667, 학습데이터 크기 : 120, 검증데이터 크기: 30\n",
      "#2 검증세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차검증 정확도:0.8667, 학습데이터 크기 : 120, 검증데이터 크기: 30\n",
      "#3 검증세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차검증 정확도:0.9333, 학습데이터 크기 : 120, 검증데이터 크기: 30\n",
      "#4 검증세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차검증 정확도:0.7333, 학습데이터 크기 : 120, 검증데이터 크기: 30\n",
      "#5 검증세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " ## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter =0 \n",
    "\n",
    "# KFold 객체의 split()을 호출하면 폴드별 학습용 , 검증용 테스트의 row 인덱스를 array로 반환 \n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # 반환된 인덱스를 이용해 학습용 , 검증용 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습 및 예측 \n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1 \n",
    "\n",
    "    # 반복시 마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차검증 정확도:{1}, 학습데이터 크기 : {2}, 검증데이터 크기: {3}'\n",
    "         .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    # 검증 데이터 인덱스는 매 번 변함 5 4 3 2 1 \n",
    "    cv_accuracy.append(accuracy)\n",
    "    # 세트별 정확도를 리스트에 추가 \n",
    "    \n",
    "# 개별 iteration 별 정확도 합하여 평균 정확도 계산 (최종 평가 )\n",
    "print('\\n ## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f5509",
   "metadata": {},
   "source": [
    "##### Stratified K 폴드 \n",
    ": 불균형한 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K폴드 방식  \n",
    "ex) 대출 사기 데이터 (사기 :1, 정상 :0) 사기(1) 의 비율 매우 적겠죠잉  \n",
    "-> 랜덤하게 학습 및 테스트 분할해도 0과 1의 비율 반영 x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7624ab33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kfold \n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "iris_df= pd.DataFrame(data =iris ,columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe5b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증 : 1\n",
      "학습 레이블 데이터 분포: \n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차검증 : 2\n",
      "학습 레이블 데이터 분포: \n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차검증 : 3\n",
      "학습 레이블 데이터 분포: \n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits =3 )\n",
    "n_iter = 0\n",
    "#for 루프 ,학습 및 테스트 데이터 인덱스 추출\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포: \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포: \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd98bae",
   "metadata": {},
   "source": [
    "##### 교차 검증시 마다 학습레이블과 검증레이블이 완전히 다른값으로 추출 됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9020b79",
   "metadata": {},
   "source": [
    "### stratifiedKFold로 전체 레이블 값의 분포도 반영 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65f0d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증 : 1\n",
      "학습 레이블 데이터 분포: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차검증 : 2\n",
      "학습 레이블 데이터 분포: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차검증 : 3\n",
      "학습 레이블 데이터 분포: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits =3)\n",
    "n_iter = 0 \n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):  # split인자로 피처 데이터 + 레이블 데이터 \n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포: \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포: \\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1d5ea",
   "metadata": {},
   "source": [
    "##### 학습레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6292b9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차검증 정확도 :0.98, 학습 데이터 크기 : 100, 검증데이터 크기 : 50\n",
      "#1, 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차검증 정확도 :0.94, 학습 데이터 크기 : 100, 검증데이터 크기 : 50\n",
      "#2, 검증 세트 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차검증 정확도 :0.98, 학습 데이터 크기 : 100, 검증데이터 크기 : 50\n",
      "#3, 검증 세트 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도 : [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도 : 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 교차검증 수행 \n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3 )\n",
    "n_iter = 0 \n",
    "cv_accuracy =[] # 교차검증 별 정확도 담을 리스트 \n",
    "\n",
    "for train_index, test_index in skfold.split(features , label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    # 학습과 예측 \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # 분할 반복시 마다 정확도 측정 \n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차검증 정확도 :{1}, 학습 데이터 크기 : {2}, 검증데이터 크기 : {3}'\n",
    "         .format(n_iter, accuracy , train_size, test_size))\n",
    "    print('#{0}, 검증 세트 인덱스 : {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "# 교차 검증별 정확도 및 평균 정확도 계산 \n",
    "print('\\n## 교차 검증별 정확도 :', np.round(cv_accuracy,4))\n",
    "print('## 평균 검증 정확도 :', np.mean(cv_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362cc57",
   "metadata": {},
   "source": [
    "### 교차 검증 간편하게 : cross_val_score() \n",
    "##### cross_val_score(estimator, X (features), y(label) , scoring = (성능 평가 지표) , cv( 교차검증 폴드수 ) . . .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f91029ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 별 정확도 : [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris \n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state =157)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 평가 지표 acuuracy, 교차 검증 세트 3개 \n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv =3)\n",
    "print('교차 검증 별 정확도 :', np.round(scores,4))\n",
    "print('평균 검증 정확도 : ', np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a74f3",
   "metadata": {},
   "source": [
    "### GridSearchCV : 교차검증 & 최적 하이퍼 파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9f58df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "# 데이터 로딩 , 데이터 분리 (학습 / 테스트)\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train , y_test = train_test_split(iris_data.data , iris_data.target,\n",
    "                                                    test_size = 0.2 , random_state= 121)\n",
    "dtree = DecisionTreeClassifier()    # estimator 객체 \n",
    "\n",
    "### 파라미터를 딕셔너리 형태로 설정 \n",
    "parameters = {'max_depth' : [1,2,3], 'min_samples_split' : [2,3] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3384dc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# pram_grid의 하이퍼 파라미터를 3개의 train/ test set 폴드로 나누어 테스트 수행 설정 \n",
    "grid_dtree= GridSearchCV(dtree, param_grid =parameters , cv =3 , refit =True)\n",
    "\n",
    "# 학습데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습 평가 수행 \n",
    "grid_dtree.fit(X_train, y_train)\n",
    "# 결과는 .cv_results_ 속성에 기록됨 \n",
    "\n",
    "# GridSearchCV의 결과를 추출해 df로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8a040",
   "metadata": {},
   "source": [
    "### 총 6번 파라미터를 변경하며 학습 및 평가를 수행 \n",
    "* params : 수행할 때마다 적용된 개별 하이퍼 파라미터 값  \n",
    "* rank_test_score : 결과 예측 성능 순위  (1 - 최적 하이퍼파라미터)   \n",
    "* meant_test_score : 개별 하이퍼 파라미터별로 cv의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값  \n",
    "4,5가 공동 1위 성능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7457a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
